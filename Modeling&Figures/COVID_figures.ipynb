{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from dateutil import parser\n",
    "import datetime\n",
    "from scipy import stats\n",
    "import math\n",
    "from scipy.stats import ks_2samp \n",
    "\n",
    "# initialise current year and month \n",
    "year = datetime.datetime.today().year\n",
    "print(\"current year: \", year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge tweet files\n",
    "before = pd.read_csv(\"covid_before_tweets.csv\", sep = \"|\").drop(columns = ['Unnamed: 0'])\n",
    "before = before.dropna(subset = ['public_metrics.retweet_count'])\n",
    "before = before[before.author_id != 'en']\n",
    "before['author_id'] = before.apply(lambda row: int(row.author_id), axis = 1)\n",
    "before['created_at'] = before.apply(lambda row: parser.parse(row.created_at), axis = 1)\n",
    "print(\"number of tweets before invasion: \", len(before))\n",
    "print(\"number of unique users based on tweets: \", len(before.author_id.unique()))\n",
    "before['author_id'] = before.apply(lambda row: int(row.author_id), axis = 1)\n",
    "\n",
    "# merge user files\n",
    "users_before = pd.read_csv(\"covid_before_users.csv\", sep = \"|\").drop(columns = ['Unnamed: 0', 'withheld.country_codes', 'withheld.scope']).drop_duplicates(subset = ['id'], keep = 'first').rename(columns = {\"id\" : \"author_id\", \"created_at\" : \"account_age\"})\n",
    "users_before['account_age'] = users_before.apply(lambda row: parser.parse(row.account_age), axis = 1)\n",
    "users_before['account_age_y'] = users_before.apply(lambda row: year - row['account_age'].year, axis = 1)\n",
    "\n",
    "# combine tweets and users\n",
    "before_covid_data = before.join(users_before.set_index('author_id'), on = ['author_id'])\n",
    "before_covid_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge tweet files\n",
    "after1 = pd.read_csv(\"covid_after_tweets.csv\", sep = \"|\").drop(columns = ['Unnamed: 0'])\n",
    "# after1['created_at'] = after1.apply(lambda row: parser.parse(row.created_at), axis = 1)\n",
    "after2 = pd.read_csv(\"covid_afterEXTRA_tweets.csv\", sep = \"|\").drop(columns = ['Unnamed: 0'])\n",
    "after_tweets = pd.concat([after1, after2])\n",
    "after_tweets = after_tweets.dropna(subset=['public_metrics.retweet_count'])\n",
    "after_tweets = after_tweets[after_tweets.author_id != 'en']\n",
    "# after_tweets['created_at'] = after_tweets.apply(lambda row: parser.parse(row.created_at), axis = 1)\n",
    "\n",
    "print(\"number of tweets after covid: \", len(after_tweets))\n",
    "print(\"number of unique users based on tweets: \", len(after_tweets.author_id.unique()))\n",
    "\n",
    "# merge user files\n",
    "users_after1 = pd.read_csv(\"covid_after_users.csv\", sep = \"|\").drop(columns = ['Unnamed: 0', 'withheld.country_codes', 'withheld.scope']).drop_duplicates(subset = ['id'], keep = 'first').rename(columns = {\"id\" : \"author_id\", \"created_at\" : \"account_age\"})\n",
    "users_after2 = pd.read_csv(\"covid_afterEXTRA_users.csv\", sep = \"|\").drop(columns = ['Unnamed: 0', 'withheld.country_codes']).drop_duplicates(subset = ['id'], keep = 'first').rename(columns = {\"id\" : \"author_id\", \"created_at\" : \"account_age\"})\n",
    "users_after = pd.concat([users_after1, users_after2]).drop_duplicates(subset = ['author_id'], keep = 'first')\n",
    "users_after['account_age'] = users_after.apply(lambda row: parser.parse(row.account_age), axis = 1)\n",
    "users_after['account_age_y'] = users_after.apply(lambda row: year - row['account_age'].year, axis = 1)\n",
    "\n",
    "# combine tweets and users\n",
    "after_covid_data = after_tweets.join(users_after.set_index('author_id'), on = ['author_id'])\n",
    "after_covid_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only with user data\n",
    "after_covid_data = after_covid_data.dropna(subset = ['public_metrics.followers_count'])\n",
    "after_covid_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only with user data\n",
    "before_covid_data = before_covid_data.dropna(subset = ['public_metrics.followers_count'])\n",
    "before_covid_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "before_covid_data['public_metrics.followers_count'] = before_covid_data.apply(lambda row: int(row['public_metrics.followers_count']), axis = 1)\n",
    "before_covid_data['public_metrics.retweet_count'] = before_covid_data.apply(lambda row: int(row['public_metrics.retweet_count']), axis = 1)\n",
    "before_covid_data['public_metrics.like_count'] = before_covid_data.apply(lambda row: int(row['public_metrics.like_count']), axis = 1)\n",
    "before_covid_data['public_metrics.reply_count'] = before_covid_data.apply(lambda row: int(row['public_metrics.reply_count']), axis = 1)\n",
    "\n",
    "after_covid_data['public_metrics.followers_count'] = after_covid_data.apply(lambda row: int(row['public_metrics.followers_count']), axis = 1)\n",
    "after_covid_data['public_metrics.retweet_count'] = after_covid_data.apply(lambda row: int(row['public_metrics.retweet_count']), axis = 1)\n",
    "after_covid_data['public_metrics.like_count'] = after_covid_data.apply(lambda row: int(row['public_metrics.like_count']), axis = 1)\n",
    "after_covid_data['public_metrics.reply_count'] = after_covid_data.apply(lambda row: int(row['public_metrics.reply_count']), axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retweet_group(data, groups):\n",
    "    for item in groups:\n",
    "        left = groups[item][0]\n",
    "        right = groups[item][1]\n",
    "        \n",
    "        # check if datapoint belongs to group\n",
    "        if (data >= left) & (data < right):\n",
    "            return item\n",
    "        \n",
    "# assign tweets to retweet class\n",
    "groups = {1 : [0, 1], 2 : [1, 10], 3 : [10, 100], 4 : [100, 1000], 5 : [1000, 100000000000]}\n",
    "before_covid_data['retweet_class'] = before_covid_data.apply(lambda row: retweet_group(row['public_metrics.retweet_count'], groups), axis = 1)\n",
    "after_covid_data['retweet_class'] = after_covid_data.apply(lambda row: retweet_group(row['public_metrics.retweet_count'], groups), axis = 1)\n",
    "print(\"count retweet classes BEFORE\", before_covid_data.groupby('retweet_class').count()['id'])\n",
    "print(\"count retweet classes AFTER\", after_covid_data.groupby('retweet_class').count()['id'])\n",
    "\n",
    "before_covid_data['retweet_bool'] = before_covid_data.apply(lambda row: 1 if row['public_metrics.retweet_count'] > 0 else 0, axis = 1)\n",
    "after_covid_data['retweet_bool'] = after_covid_data.apply(lambda row: 1 if row['public_metrics.retweet_count'] > 0 else 0, axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set()\n",
    "max_listed_before = before_covid_data['public_metrics.followers_count'].max()\n",
    "max_listed_after = after_covid_data['public_metrics.followers_count'].max()\n",
    "edges_new = np.logspace(np.log10(1),np.log10(max(max_listed_before, max_listed_after)), 20)\n",
    "edges_new[0] = 0\n",
    "\n",
    "\n",
    "bin_means1_retweet, bin_edges, binnumber_b = stats.binned_statistic(before_covid_data['public_metrics.followers_count'], before_covid_data['public_metrics.retweet_count'], statistic = 'mean', bins = edges_new)\n",
    "bin_means2_retweet, bin_edges, binnumber_a = stats.binned_statistic(after_covid_data['public_metrics.followers_count'], after_covid_data['public_metrics.retweet_count'], statistic = 'mean', bins = edges_new)\n",
    "\n",
    "after_covid_data['bin'] = binnumber_a\n",
    "before_covid_data['bin'] = binnumber_b\n",
    "\n",
    "# create mean value of each bin for x-axis\n",
    "x = list()\n",
    "for i in range(len(edges_new) - 1):\n",
    "    left = edges_new[i]\n",
    "    right = edges_new[i + 1]\n",
    "    x.append((right - left) / 2 + left)\n",
    "\n",
    "retweet_class = {1 : 'no retweets', 2 : '1-9 retweets', 3 : '10-99 retweets', 4 : '100-999 retweets', 5 : '1000+ retweets', 6 : 'at least 1 retweet'}\n",
    "rt_class = 1\n",
    "\n",
    "fig, axs = plt.subplots(2, 3, figsize = (17,8))\n",
    "\n",
    "for row in [0,1]:\n",
    "    for column in [0,1,2]:\n",
    "        \n",
    "        if rt_class == 6:\n",
    "            binned_before = before_covid_data[before_covid_data['retweet_class'] > 1].groupby(\"bin\").count()['public_metrics.retweet_count'] / before_covid_data[before_covid_data['retweet_class'] > 1].count()['id']\n",
    "            binned_after = after_covid_data[after_covid_data['retweet_class'] > 1].groupby(\"bin\").count()['public_metrics.retweet_count'] / after_covid_data[after_covid_data['retweet_class'] > 1].count()['id']\n",
    "        else:     \n",
    "            binned_before = before_covid_data[before_covid_data['retweet_class'] == rt_class].groupby(\"bin\").count()['public_metrics.retweet_count'] / before_covid_data[before_covid_data['retweet_class'] == rt_class].count()['id']\n",
    "            binned_after = after_covid_data[after_covid_data['retweet_class'] == rt_class].groupby(\"bin\").count()['public_metrics.retweet_count'] / after_covid_data[after_covid_data['retweet_class'] == rt_class].count()['id']\n",
    "\n",
    "        axs[row, column].plot(np.array(x)[[item - 1 for item in binned_before.index]], binned_before, label = 'before invasion', color = 'b')\n",
    "        axs[row, column].plot(np.array(x)[[item - 1 for item in binned_after.index]], binned_after, label = 'after invasion', color = 'r')\n",
    "        axs[row, column].set_title(\"COVID prob. distr. - \"+ retweet_class[rt_class])\n",
    "        axs[row, column].set_ylabel('fraction of retweets from class')\n",
    "        axs[row, column].set_xlabel('followers count increasing (log)')\n",
    "        axs[row, column].set_xscale('symlog')\n",
    "        axs[row, column].set_xlim(1, 200000000)\n",
    "        \n",
    "        rt_class = rt_class + 1\n",
    "    axs[0,0].legend(loc = 'upper right')\n",
    "    \n",
    "fig.tight_layout()\n",
    "# fig.savefig(\"COVID_distribution_retweetclasses.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set()\n",
    "viral_binned_before = before_covid_data[before_covid_data['retweet_class'] > 3].groupby(\"bin\").count()['id'] / before_covid_data[before_covid_data['retweet_class'] > 3].count()['id']\n",
    "viral_binned_after = after_covid_data[after_covid_data['retweet_class'] > 3].groupby(\"bin\").count()['id'] / after_covid_data[after_covid_data['retweet_class'] > 3].count()['id']\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "                                                                                                                            \n",
    "ax.plot(np.array(x)[[item - 1 for item in viral_binned_before.index]], viral_binned_before, label = 'before invasion', color = 'b')\n",
    "ax.plot(np.array(x)[[item - 1 for item in viral_binned_after.index]], viral_binned_after, label = 'after invasion', color = 'r')\n",
    "ax.legend(loc = 'upper left', fontsize = 15)\n",
    "ax.set_title('COVID - Fraction of viral tweets for number of followers', size = 13, weight = 'bold')\n",
    "ax.set_xlabel('followers increasing (log)', size = 12)\n",
    "ax.set_ylabel('fraction of viral tweets', size = 12)\n",
    "ax.set_xscale('symlog')\n",
    "fig.tight_layout()\n",
    "fig.savefig(\"COVID_viral_followers.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_listed_before = before_covid_data['public_metrics.listed_count'].max()\n",
    "max_listed_after = after_covid_data['public_metrics.listed_count'].max()\n",
    "edges_new = np.logspace(np.log10(1),np.log10(max(max_listed_before, max_listed_after)), 20)\n",
    "edges_new[0] = 0\n",
    "\n",
    "\n",
    "bin_means1_retweet, bin_edges, binnumber_b = stats.binned_statistic(before_covid_data['public_metrics.listed_count'], before_covid_data['public_metrics.retweet_count'], statistic = 'mean', bins = edges_new)\n",
    "bin_means2_retweet, bin_edges, binnumber_a = stats.binned_statistic(after_covid_data['public_metrics.listed_count'], after_covid_data['public_metrics.retweet_count'], statistic = 'mean', bins = edges_new)\n",
    "\n",
    "after_covid_data['bin'] = binnumber_a\n",
    "before_covid_data['bin'] = binnumber_b\n",
    "\n",
    "# create mean value of each bin for x-axis\n",
    "x = list()\n",
    "for i in range(len(edges_new) - 1):\n",
    "    left = edges_new[i]\n",
    "    right = edges_new[i + 1]\n",
    "    x.append((right - left) / 2 + left)\n",
    "\n",
    "retweet_class = {1 : 'no retweets', 2 : '1-9 retweets', 3 : '10-99 retweets', 4 : '100-999 retweets', 5 : '1000+ retweets', 6 : 'at least 1 retweet'}\n",
    "rt_class = 1\n",
    "\n",
    "fig, axs = plt.subplots(2, 3, figsize = (17,8))\n",
    "\n",
    "for row in [0,1]:\n",
    "    for column in [0,1,2]:\n",
    "        \n",
    "        if rt_class == 6:\n",
    "            binned_before = before_covid_data[before_covid_data['retweet_class'] > 1].groupby(\"bin\").count()['public_metrics.retweet_count'] / before_covid_data[before_covid_data['retweet_class'] > 1].count()['id']\n",
    "            binned_after = after_covid_data[after_covid_data['retweet_class'] > 1].groupby(\"bin\").count()['public_metrics.retweet_count'] / after_covid_data[after_covid_data['retweet_class'] > 1].count()['id']\n",
    "        else:     \n",
    "            binned_before = before_covid_data[before_covid_data['retweet_class'] == rt_class].groupby(\"bin\").count()['public_metrics.retweet_count'] / before_covid_data[before_covid_data['retweet_class'] == rt_class].count()['id']\n",
    "            binned_after = after_covid_data[after_covid_data['retweet_class'] == rt_class].groupby(\"bin\").count()['public_metrics.retweet_count'] / after_covid_data[after_covid_data['retweet_class'] == rt_class].count()['id']\n",
    "\n",
    "        axs[row, column].plot(np.array(x)[[item - 1 for item in binned_before.index]], binned_before, label = 'before invasion', color = 'b')\n",
    "        axs[row, column].plot(np.array(x)[[item - 1 for item in binned_after.index]], binned_after, label = 'after invasion', color = 'r')\n",
    "        axs[row, column].set_title(\"COVIDD prob. distr. - \"+ retweet_class[rt_class])\n",
    "        axs[row, column].set_ylabel('fraction of retweets from class')\n",
    "        axs[row, column].set_xlabel('listed count increasing (log)')\n",
    "        axs[row, column].set_xscale('symlog')\n",
    "#         axs[row, column].set_xlim(1, 200000000)\n",
    "#         axs[row, column].set_ylim(0, 0.3)\n",
    "        \n",
    "        rt_class = rt_class + 1\n",
    "    axs[0,0].legend(loc = 'upper right')\n",
    "    \n",
    "fig.tight_layout()\n",
    "# fig.savefig(\"distribution_retweetclasses.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set()\n",
    "viral_binned_before = before_covid_data[before_covid_data['retweet_class'] > 3].groupby(\"bin\").count()['id'] / before_covid_data[before_covid_data['retweet_class'] > 3].count()['id']\n",
    "viral_binned_after = after_covid_data[after_covid_data['retweet_class'] > 3].groupby(\"bin\").count()['id'] / after_covid_data[after_covid_data['retweet_class'] > 3].count()['id']\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "                                                                                                                            \n",
    "ax.plot(np.array(x)[[item - 1 for item in viral_binned_before.index]], viral_binned_before, label = 'before invasion', color = 'b')\n",
    "ax.plot(np.array(x)[[item - 1 for item in viral_binned_after.index]], viral_binned_after, label = 'after invasion', color = 'r')\n",
    "ax.legend(loc = 'upper left', fontsize = 15)\n",
    "ax.set_title('COVID - Fraction of viral tweets for number of listed users', size = 13, weight = 'bold')\n",
    "ax.set_xlabel('listed count increasing (log)', size = 12)\n",
    "ax.set_ylabel('fraction of viral tweets', size = 12)\n",
    "ax.set_xscale('symlog')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_listed_before = before_covid_data['public_metrics.tweet_count'].max()\n",
    "max_listed_after = after_covid_data['public_metrics.tweet_count'].max()\n",
    "edges_new = np.logspace(np.log10(1),np.log10(max(max_listed_before, max_listed_after)), 20)\n",
    "edges_new[0] = 0\n",
    "\n",
    "\n",
    "bin_means1_retweet, bin_edges, binnumber_b = stats.binned_statistic(before_covid_data['public_metrics.tweet_count'], before_covid_data['public_metrics.retweet_count'], statistic = 'mean', bins = edges_new)\n",
    "bin_means2_retweet, bin_edges, binnumber_a = stats.binned_statistic(after_covid_data['public_metrics.tweet_count'], after_covid_data['public_metrics.retweet_count'], statistic = 'mean', bins = edges_new)\n",
    "\n",
    "after_covid_data['bin'] = binnumber_a\n",
    "before_covid_data['bin'] = binnumber_b\n",
    "\n",
    "# create mean value of each bin for x-axis\n",
    "x = list()\n",
    "for i in range(len(edges_new) - 1):\n",
    "    left = edges_new[i]\n",
    "    right = edges_new[i + 1]\n",
    "    x.append((right - left) / 2 + left)\n",
    "\n",
    "retweet_class = {1 : 'no retweets', 2 : '1-9 retweets', 3 : '10-99 retweets', 4 : '100-999 retweets', 5 : '1000+ retweets', 6 : 'at least 1 retweet'}\n",
    "rt_class = 1\n",
    "\n",
    "fig, axs = plt.subplots(2, 3, figsize = (17,8))\n",
    "\n",
    "for row in [0,1]:\n",
    "    for column in [0,1,2]:\n",
    "        \n",
    "        if rt_class == 6:\n",
    "            binned_before = before_covid_data[before_covid_data['retweet_class'] > 1].groupby(\"bin\").count()['public_metrics.retweet_count'] / before_covid_data[before_covid_data['retweet_class'] > 1].count()['id']\n",
    "            binned_after = after_covid_data[after_covid_data['retweet_class'] > 1].groupby(\"bin\").count()['public_metrics.retweet_count'] / after_covid_data[after_covid_data['retweet_class'] > 1].count()['id']\n",
    "        else:     \n",
    "            binned_before = before_covid_data[before_covid_data['retweet_class'] == rt_class].groupby(\"bin\").count()['public_metrics.retweet_count'] / before_covid_data[before_covid_data['retweet_class'] == rt_class].count()['id']\n",
    "            binned_after = after_covid_data[after_covid_data['retweet_class'] == rt_class].groupby(\"bin\").count()['public_metrics.retweet_count'] / after_covid_data[after_covid_data['retweet_class'] == rt_class].count()['id']\n",
    "\n",
    "        axs[row, column].plot(np.array(x)[[item - 1 for item in binned_before.index]], binned_before, label = 'before invasion', color = 'b')\n",
    "        axs[row, column].plot(np.array(x)[[item - 1 for item in binned_after.index]], binned_after, label = 'after invasion', color = 'r')\n",
    "        axs[row, column].set_title(\"COVID prob. distr. - \"+ retweet_class[rt_class])\n",
    "        axs[row, column].set_ylabel('fraction of retweets from class')\n",
    "        axs[row, column].set_xlabel('tweet count increasing (log)')\n",
    "        axs[row, column].set_xscale('symlog')\n",
    "        \n",
    "        rt_class = rt_class + 1\n",
    "    axs[0,0].legend(loc = 'upper right')\n",
    "    \n",
    "fig.tight_layout()\n",
    "# fig.savefig(\"distribution_retweetclasses.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set()\n",
    "viral_binned_before = before_covid_data[before_covid_data['retweet_class'] > 3].groupby(\"bin\").count()['id'] / before_covid_data[before_covid_data['retweet_class'] > 3].count()['id']\n",
    "viral_binned_after = after_covid_data[after_covid_data['retweet_class'] > 3].groupby(\"bin\").count()['id'] / after_covid_data[after_covid_data['retweet_class'] > 3].count()['id']\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "                                                                                                                            \n",
    "ax.plot(np.array(x)[[item - 1 for item in viral_binned_before.index]], viral_binned_before, label = 'before invasion', color = 'b')\n",
    "ax.plot(np.array(x)[[item - 1 for item in viral_binned_after.index]], viral_binned_after, label = 'after invasion', color = 'r')\n",
    "ax.legend(loc = 'upper left', fontsize = 15)\n",
    "ax.set_title('COVID - Fraction of viral tweets for tweet count', size = 13, weight = 'bold')\n",
    "ax.set_xlabel('tweet count increasing (log)', size = 12)\n",
    "ax.set_ylabel('fraction of viral tweets', size = 12)\n",
    "ax.set_xscale('symlog')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
